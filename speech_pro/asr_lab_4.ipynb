{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "asr_lab_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f88f9bb354b04317a7f93a1585836aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68efb663da1c4e87b4311102b5237dd2",
              "IPY_MODEL_758948132df349308eba13f0a10ad058",
              "IPY_MODEL_d2a40c765bff4ec2b105ccf51c1b8b52"
            ],
            "layout": "IPY_MODEL_161487c72e5e45ffaf2f12597f9aaa03"
          }
        },
        "68efb663da1c4e87b4311102b5237dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d02c31edceb49d2b8f42191deccd762",
            "placeholder": "​",
            "style": "IPY_MODEL_6f1becbb2c0845bd9ed4eda0bcfbe38c",
            "value": "100%"
          }
        },
        "758948132df349308eba13f0a10ad058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553839595a3146bc90c13145ce5641b4",
            "max": 6387309499,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bc677c80ad9464f9fa72af731036101",
            "value": 6387309499
          }
        },
        "d2a40c765bff4ec2b105ccf51c1b8b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d5aa3d995764285a2fe0936213bce90",
            "placeholder": "​",
            "style": "IPY_MODEL_715c78d25c6d4ac5a2df80ccda8396a0",
            "value": " 5.95G/5.95G [07:22&lt;00:00, 14.1MB/s]"
          }
        },
        "161487c72e5e45ffaf2f12597f9aaa03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d02c31edceb49d2b8f42191deccd762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f1becbb2c0845bd9ed4eda0bcfbe38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "553839595a3146bc90c13145ce5641b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bc677c80ad9464f9fa72af731036101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d5aa3d995764285a2fe0936213bce90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "715c78d25c6d4ac5a2df80ccda8396a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5822f579247467cb4ae9765e1125e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff16faa485f64153a896bbe16fdcce65",
              "IPY_MODEL_9aa6afc8232b4ff3897424a816a0715e",
              "IPY_MODEL_bcccc97ae51f40c89b9cfee2fa1b8918"
            ],
            "layout": "IPY_MODEL_159a0fd356f94a81a9f6fdd9bfe4d20e"
          }
        },
        "ff16faa485f64153a896bbe16fdcce65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc2541aba61414fa774bebc0b74ab74",
            "placeholder": "​",
            "style": "IPY_MODEL_71284f0ab8124fc0b1160b53e0f55a7b",
            "value": "100%"
          }
        },
        "9aa6afc8232b4ff3897424a816a0715e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2293682598004eac91898e354711b59b",
            "max": 346663984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ae1c24cdf164d10a1f9b2fdfa4956ed",
            "value": 346663984
          }
        },
        "bcccc97ae51f40c89b9cfee2fa1b8918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79078fba5a294c97a93dba3255262e2f",
            "placeholder": "​",
            "style": "IPY_MODEL_5b635c2063274595ae3f1249e3a84343",
            "value": " 331M/331M [00:31&lt;00:00, 13.2MB/s]"
          }
        },
        "159a0fd356f94a81a9f6fdd9bfe4d20e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc2541aba61414fa774bebc0b74ab74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71284f0ab8124fc0b1160b53e0f55a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2293682598004eac91898e354711b59b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae1c24cdf164d10a1f9b2fdfa4956ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79078fba5a294c97a93dba3255262e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b635c2063274595ae3f1249e3a84343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RcyxmRJGqlY"
      },
      "source": [
        "# Практика №4\n",
        "\n",
        "Теперь мы построим и обучим простую end-to-end модель. Будем работать с пропатченной версией уже готового [пайплайна](https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch). Также нам пригодится [ESPnet](https://github.com/espnet/espnet) для использования модели [Transformer](http://jalammar.github.io/illustrated-transformer/) в качестве энкодера."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDbO_rrWGq7j"
      },
      "source": [
        "### Bootstrap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzJyomV1JaLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af234053-55fe-4776-f206-3bed01d73475"
      },
      "source": [
        "!pip install -q torchaudio sentencepiece"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 28.8 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 4.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TROAsHTXHWik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d957fb9-c14c-49d7-bb8a-5fc4603a6f01"
      },
      "source": [
        "!gdown --id '1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6'\n",
        "\n",
        "!unzip -q lab4.zip\n",
        "!rm -rf lab4.zip sample_data.\n",
        "%cd lab4"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6\n",
            "To: /content/lab4.zip\n",
            "100% 2.77M/2.77M [00:00<00:00, 174MB/s]\n",
            "/content/lab4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4wcCtkIH2dn"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from sentencepiece import SentencePieceProcessor, SentencePieceTrainer\n",
        "\n",
        "from utils import TextTransform\n",
        "from utils import cer\n",
        "from utils import wer\n",
        "\n",
        "from espnet.nets.pytorch_backend.transformer.embedding import PositionalEncoding\n",
        "from espnet.nets.pytorch_backend.transformer.encoder_layer import EncoderLayer\n",
        "from espnet.nets.pytorch_backend.transformer.repeat import repeat\n",
        "from espnet.nets.pytorch_backend.transformer.attention import MultiHeadedAttention\n",
        "from espnet.nets.pytorch_backend.transformer.positionwise_feed_forward import PositionwiseFeedForward\n",
        "from espnet.nets.pytorch_backend.transformer.layer_norm import LayerNorm\n",
        "from espnet.nets.pytorch_backend.nets_utils import make_pad_mask"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "XHKuY8HnAC4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae5dc60-bbc3-4839-ceee-cc558cbad039"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun  7 12:18:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaESUZiHJgfN"
      },
      "source": [
        "train_audio_transforms = torch.nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=400, hop_length=160, n_mels=80),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
        "                                                              n_fft=400,\n",
        "                                                              hop_length=160,\n",
        "                                                              n_mels=80)\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "#-----------------------------TODO №2-----------------------------------\n",
        "# Заменить графемный токенайзер на сабвордовый TextTransformBPE\n",
        "#-----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0])\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = torch.nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "    arg_maxes = torch.argmax(output, dim=2)\n",
        "    decodes = []\n",
        "    targets = []\n",
        "    for i, args in enumerate(arg_maxes):\n",
        "        decode = []\n",
        "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "        for j, index in enumerate(args):\n",
        "            if index != blank_label:\n",
        "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
        "                    continue\n",
        "                decode.append(index.item())\n",
        "        decodes.append(text_transform.int_to_text(decode))\n",
        "    return decodes, targets"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OqoVLnrJsCV"
      },
      "source": [
        "class TransformerModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=80,\n",
        "        output_size=29,\n",
        "        conv2d_filters=32,\n",
        "        attention_dim=240,\n",
        "        attention_heads=8,\n",
        "        feedforward_dim=512,\n",
        "        num_layers=8,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        \n",
        "        self.conv_in = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(conv2d_filters, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "        self.conv_out = torch.nn.Sequential(\n",
        "            torch.nn.Linear(conv2d_filters * (input_size // 4), attention_dim),\n",
        "            PositionalEncoding(attention_dim, 0.1),\n",
        "        )\n",
        "        positionwise_layer = PositionwiseFeedForward\n",
        "        positionwise_layer_args = (attention_dim, feedforward_dim, dropout)\n",
        "        self.encoder_layer = repeat(\n",
        "            num_layers,\n",
        "            lambda lnum: EncoderLayer(\n",
        "                attention_dim,\n",
        "                MultiHeadedAttention(\n",
        "                    attention_heads, attention_dim, dropout\n",
        "                ),\n",
        "                positionwise_layer(*positionwise_layer_args),\n",
        "                dropout,\n",
        "                normalize_before=True,\n",
        "                concat_after=False,\n",
        "            ),\n",
        "        )\n",
        "        self.after_norm = LayerNorm(attention_dim)\n",
        "        self.final_layer = torch.nn.Linear(attention_dim, output_size)\n",
        "\n",
        "    def forward(self, x, ilens):\n",
        "        x = x.unsqueeze(1)  # (b, c, t, f)\n",
        "        x = self.conv_in(x)\n",
        "        b, c, t, f = x.size()\n",
        "        x = self.conv_out(x.transpose(1, 2).contiguous().view(b, t, c * f))\n",
        "        masks = (~make_pad_mask(ilens)[:, None, :])[:, :, ::4].to(x.device)\n",
        "        x, _ = self.encoder_layer(x, masks)\n",
        "        x = self.after_norm(x)\n",
        "        x = self.final_layer(x)\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 800, 80)\n",
        "model = TransformerModel()\n",
        "output = model(x, [800, 90])\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "mhbOKdLLbXHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0bbee45-22ef-4c9e-bcad-974917933776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 200, 29])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2p_8IjeKkqq"
      },
      "source": [
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms[:, :, :,:max(input_lengths)].to(device), labels.to(device) #(batch, 1, feat_dim, time)\n",
        "        spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch, time, feat_dim,)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(spectrograms, input_lengths)  # (batch, time, n_classes)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "        input_lengths = [x // 4 for x in input_lengths]\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if batch_idx % 500 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLR: {:.6f}'.format(\n",
        "                epoch,\n",
        "                batch_idx * len(spectrograms),\n",
        "                data_len,\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item(),\n",
        "                scheduler.get_last_lr()[0]))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, blank_label, decode=True):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "            spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch time, feat_dim,)\n",
        "            \n",
        "            output = model(spectrograms, input_lengths)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "            input_lengths = [x // 4 for x in input_lengths]\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            if decode:\n",
        "              decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths, blank_label=blank_label)\n",
        "              for j in range(len(decoded_preds)):\n",
        "                  test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                  test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "    if decode:\n",
        "        avg_cer = sum(test_cer)/len(test_cer)\n",
        "        avg_wer = sum(test_wer)/len(test_wer)\n",
        "\n",
        "        print(f\"Test set: Average loss: {test_loss:.4f}, Average CER: {avg_cer:4f} Average WER: {avg_wer:.4f}\\n\")\n",
        "    else:\n",
        "        print(f\"Average loss: {test_loss:.4f}\\n\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzEbtsB1LKsh"
      },
      "source": [
        "def main(hparams, test_batch_size=7, train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
        "    \n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=test_batch_size,\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "    model = TransformerModel(\n",
        "        hparams['input_size'],\n",
        "        hparams['output_size'],\n",
        "        hparams['conv2d_filters'],\n",
        "        hparams['attention_dim'],\n",
        "        hparams['attention_heads'],\n",
        "        hparams['feedforward_dim'],\n",
        "        hparams['num_layers'],\n",
        "        hparams['dropout']).to(device)\n",
        "\n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = torch.nn.CTCLoss(blank=hparams['output_size']-1, zero_infinity=False).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "    \n",
        "    for epoch in range(1, hparams['epochs'] + 1):\n",
        "        !date\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
        "        test(model, device, test_loader, criterion, epoch, blank_label=hparams['output_size']-1, decode=not(epoch % 2))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = {\n",
        "    \"input_size\": 80,\n",
        "    \"output_size\": 29,\n",
        "    \"conv2d_filters\": 32,\n",
        "    \"attention_dim\": 320,\n",
        "    \"attention_heads\": 8,\n",
        "    \"feedforward_dim\": 1024,\n",
        "    \"num_layers\": 10,\n",
        "    \"dropout\": 0.1,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 10,\n",
        "    \"epochs\": 10\n",
        "}\n",
        "\n",
        "test_batch_size = 7\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\""
      ],
      "metadata": {
        "id": "ZfJP-Jdunzr9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eExZLsUiLeXk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f88f9bb354b04317a7f93a1585836aca",
            "68efb663da1c4e87b4311102b5237dd2",
            "758948132df349308eba13f0a10ad058",
            "d2a40c765bff4ec2b105ccf51c1b8b52",
            "161487c72e5e45ffaf2f12597f9aaa03",
            "0d02c31edceb49d2b8f42191deccd762",
            "6f1becbb2c0845bd9ed4eda0bcfbe38c",
            "553839595a3146bc90c13145ce5641b4",
            "2bc677c80ad9464f9fa72af731036101",
            "8d5aa3d995764285a2fe0936213bce90",
            "715c78d25c6d4ac5a2df80ccda8396a0",
            "c5822f579247467cb4ae9765e1125e49",
            "ff16faa485f64153a896bbe16fdcce65",
            "9aa6afc8232b4ff3897424a816a0715e",
            "bcccc97ae51f40c89b9cfee2fa1b8918",
            "159a0fd356f94a81a9f6fdd9bfe4d20e",
            "6cc2541aba61414fa774bebc0b74ab74",
            "71284f0ab8124fc0b1160b53e0f55a7b",
            "2293682598004eac91898e354711b59b",
            "8ae1c24cdf164d10a1f9b2fdfa4956ed",
            "79078fba5a294c97a93dba3255262e2f",
            "5b635c2063274595ae3f1249e3a84343"
          ]
        },
        "outputId": "6aaac1cb-f525-47e3-f623-654e6d9ddab9"
      },
      "source": [
        "main(hparams, test_batch_size, libri_train_set, libri_test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f88f9bb354b04317a7f93a1585836aca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/5.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5822f579247467cb4ae9765e1125e49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerModel(\n",
            "  (conv_in): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (encoder_layer): MultiSequential(\n",
            "    (0): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (1): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (2): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (3): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (4): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (5): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (6): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (7): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (8): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (9): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "  (final_layer): Linear(in_features=320, out_features=29, bias=True)\n",
            ")\n",
            "Num Model Parameters 10913277\n",
            "Sat Jun  4 11:17:10 UTC 2022\n",
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 4.720305\tLR: 0.000040\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.728180\tLR: 0.000096\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.797333\tLR: 0.000152\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.565108\tLR: 0.000208\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 2.321352\tLR: 0.000264\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 2.348033\tLR: 0.000320\n",
            "\n",
            "evaluating...\n",
            "Average loss: 2.1877\n",
            "\n",
            "Sat Jun  4 11:27:39 UTC 2022\n",
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 2.068218\tLR: 0.000360\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 2.243146\tLR: 0.000416\n",
            "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 2.087751\tLR: 0.000472\n",
            "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 2.164885\tLR: 0.000528\n",
            "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 2.011943\tLR: 0.000584\n",
            "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 1.971940\tLR: 0.000640\n",
            "\n",
            "evaluating...\n",
            "Average loss: 1.9048\n",
            "\n",
            "Sat Jun  4 11:38:09 UTC 2022\n",
            "Train Epoch: 3 [0/28539 (0%)]\tLoss: 2.055739\tLR: 0.000680\n",
            "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 1.971916\tLR: 0.000736\n",
            "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 1.945171\tLR: 0.000792\n",
            "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 1.696344\tLR: 0.000848\n",
            "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 1.815014\tLR: 0.000904\n",
            "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 1.983553\tLR: 0.000961\n",
            "\n",
            "evaluating...\n",
            "Average loss: 1.5565\n",
            "\n",
            "Sat Jun  4 11:48:37 UTC 2022\n",
            "Train Epoch: 4 [0/28539 (0%)]\tLoss: 1.735469\tLR: 0.001000\n",
            "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 1.562307\tLR: 0.000975\n",
            "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 1.535154\tLR: 0.000950\n",
            "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 1.720774\tLR: 0.000925\n",
            "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 1.541245\tLR: 0.000900\n",
            "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 1.567722\tLR: 0.000875\n",
            "\n",
            "evaluating...\n",
            "Average loss: 1.2308\n",
            "\n",
            "Sat Jun  4 11:59:06 UTC 2022\n",
            "Train Epoch: 5 [0/28539 (0%)]\tLoss: 1.589002\tLR: 0.000857\n",
            "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 1.305328\tLR: 0.000832\n",
            "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 1.370997\tLR: 0.000807\n",
            "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 1.208585\tLR: 0.000782\n",
            "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 1.572865\tLR: 0.000757\n",
            "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 1.250990\tLR: 0.000732\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.0431, Average CER: 0.267926 Average WER: 0.7346\n",
            "\n",
            "Sat Jun  4 12:14:55 UTC 2022\n",
            "Train Epoch: 6 [0/28539 (0%)]\tLoss: 1.142578\tLR: 0.000714\n",
            "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 1.415033\tLR: 0.000689\n",
            "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 1.327416\tLR: 0.000664\n",
            "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 1.375285\tLR: 0.000639\n",
            "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 1.249333\tLR: 0.000614\n",
            "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 1.214466\tLR: 0.000589\n",
            "\n",
            "evaluating...\n",
            "Average loss: 0.9302\n",
            "\n",
            "Sat Jun  4 12:25:17 UTC 2022\n",
            "Train Epoch: 7 [0/28539 (0%)]\tLoss: 1.316122\tLR: 0.000571\n",
            "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 1.358996\tLR: 0.000546\n",
            "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 1.262120\tLR: 0.000521\n",
            "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 0.959449\tLR: 0.000496\n",
            "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 1.219389\tLR: 0.000471\n",
            "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 1.162258\tLR: 0.000446\n",
            "\n",
            "evaluating...\n",
            "Average loss: 0.8425\n",
            "\n",
            "Sat Jun  4 12:35:45 UTC 2022\n",
            "Train Epoch: 8 [0/28539 (0%)]\tLoss: 1.025664\tLR: 0.000428\n",
            "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 1.115155\tLR: 0.000403\n",
            "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 1.291131\tLR: 0.000378\n",
            "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 0.975140\tLR: 0.000353\n",
            "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 1.035513\tLR: 0.000328\n",
            "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 1.122392\tLR: 0.000303\n",
            "\n",
            "evaluating...\n",
            "Average loss: 0.7686\n",
            "\n",
            "Sat Jun  4 12:46:12 UTC 2022\n",
            "Train Epoch: 9 [0/28539 (0%)]\tLoss: 0.958617\tLR: 0.000286\n",
            "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 0.973497\tLR: 0.000261\n",
            "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.959346\tLR: 0.000236\n",
            "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.976148\tLR: 0.000211\n",
            "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 0.980563\tLR: 0.000186\n",
            "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 1.104461\tLR: 0.000160\n",
            "\n",
            "evaluating...\n",
            "Average loss: 0.7169\n",
            "\n",
            "Sat Jun  4 12:56:40 UTC 2022\n",
            "Train Epoch: 10 [0/28539 (0%)]\tLoss: 0.934696\tLR: 0.000143\n",
            "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.809339\tLR: 0.000118\n",
            "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 0.997191\tLR: 0.000093\n",
            "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 0.965480\tLR: 0.000068\n",
            "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.846275\tLR: 0.000043\n",
            "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.860135\tLR: 0.000018\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.6905, Average CER: 0.183968 Average WER: 0.5550\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mby39YVqZadd"
      },
      "source": [
        "### <b>Задание №1</b> (5 баллов):\n",
        "На данный момент практически все E2E SOTA решения используют [сабворды](https://dyakonov.org/2019/11/29/%D1%82%D0%BE%D0%BA%D0%B5%D0%BD%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-%D0%BD%D0%B0-%D0%BF%D0%BE%D0%B4%D1%81%D0%BB%D0%BE%D0%B2%D0%B0-subword-tokenization/) (subwords/wordpieces) в качестве таргетов нейронки для распознавания. Нам бы тоже не мешало перейти от графем к сабвордам. Теперь вместо букв (графем) будем распознавать кусочки слов. В качестве такого токенайзера предлагается использовать [Sentencepiece](https://github.com/google/sentencepiece). Пример обучения BPE токенайзера можно найти в [link](https://github.com/google/sentencepiece/tree/master/python). Главное правильно обернуть его в наш класс TextTransformBPE. Текстовый файл (train_clean_100_text_clean.txt) для обучения токенайзера уже подготовлен и лежит в корневой папке проекта. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ответ**:"
      ],
      "metadata": {
        "id": "DVkqYhE-w5jn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNbiW919e2le"
      },
      "source": [
        "class TextTransformBPE:\n",
        "    def __init__(self, train_text, vocab_size=2000):\n",
        "        \"\"\" Обучение BPE модели на 2000 юнитов\"\"\"\n",
        "        SentencePieceTrainer.train(\n",
        "            input=train_text,\n",
        "            vocab_size=vocab_size,\n",
        "            model_type='bpe',\n",
        "            model_prefix='m',\n",
        "            normalization_rule_name='nfkc_cf',\n",
        "        )\n",
        "        self.model = SentencePieceProcessor(model_file='m.model')\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Преобразование входного текста в последовательность сабвордов в формате их индекса в BPE модели \"\"\"\n",
        "        int_sequence = self.model.encode_as_ids(text)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Преобразование последовательности индексов сабвордов в текст \"\"\"\n",
        "        string = self.model.decode(list(map(int, labels)))\n",
        "        return string"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = TextTransformBPE(train_text='train_clean_100_text_clean.txt')"
      ],
      "metadata": {
        "id": "_649zCoowcEA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hparams['output_size'] = 2001\n",
        "main(hparams, test_batch_size, libri_train_set, libri_test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N8LSc_Mxwzn_",
        "outputId": "a98c2a5c-b60e-4873-c7bf-a49d1d136cb6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerModel(\n",
            "  (conv_in): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (encoder_layer): MultiSequential(\n",
            "    (0): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (1): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (2): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (3): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (4): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (5): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (6): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (7): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (8): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (9): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "  (final_layer): Linear(in_features=320, out_features=2001, bias=True)\n",
            ")\n",
            "Num Model Parameters 11546289\n",
            "Tue Jun  7 14:51:08 UTC 2022\n",
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 39.770519\tLR: 0.000040\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 6.655106\tLR: 0.000096\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 6.731977\tLR: 0.000152\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 6.550679\tLR: 0.000208\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 6.534608\tLR: 0.000264\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 6.257268\tLR: 0.000320\n",
            "Average loss: 6.1401\n",
            "\n",
            "Tue Jun  7 15:02:01 UTC 2022\n",
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 6.253027\tLR: 0.000360\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 6.004383\tLR: 0.000416\n",
            "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 5.692730\tLR: 0.000472\n",
            "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 5.356878\tLR: 0.000528\n",
            "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 5.298561\tLR: 0.000584\n",
            "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 4.959370\tLR: 0.000640\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 4.5992, Average CER: 0.781516 Average WER: 0.8792\n",
            "\n",
            "Tue Jun  7 15:14:37 UTC 2022\n",
            "Train Epoch: 3 [0/28539 (0%)]\tLoss: 4.749438\tLR: 0.000680\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a4785bb0d5bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibri_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibri_test_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-bde1c141b7d6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(hparams, test_batch_size, train_url, test_url)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblank_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-6fe520bed79b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оно обучается) На первых эпохах лосс выше чем в обычной модели, но скорее всего при большом числе эпох лосс будет ниже, чем у прошлой модели"
      ],
      "metadata": {
        "id": "UdtB3ueR1xsP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV48Q7HqZsAD"
      },
      "source": [
        "### <b>Задание №2</b> (5 баллов):\n",
        "Импровизация по улучшению качества распознавания."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ответ**:"
      ],
      "metadata": {
        "id": "N1OBVhLgATV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изменение параметров:\n",
        "```\n",
        "hparams = {\n",
        "    \"input_size\": 80,\n",
        "    \"output_size\": 2001 -> 4001,\n",
        "    \"conv2d_filters\": 32,\n",
        "    \"attention_dim\": 320 -> 360,\n",
        "    \"attention_heads\": 8 -> 4,\n",
        "    \"feedforward_dim\": 1024,\n",
        "    \"num_layers\": 10 -> 16,\n",
        "    \"dropout\": 0.1 -> 0.2,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 10,\n",
        "    \"epochs\": 10 -> 20\n",
        "}\n",
        "```\n",
        "\n",
        "Модель имеет почти в 2 раза больше параметров, поэтому ее необходимо дольше учить"
      ],
      "metadata": {
        "id": "w1csMxN82-Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = {\n",
        "    \"input_size\": 80,\n",
        "    \"output_size\": 4001,\n",
        "    \"conv2d_filters\": 32,\n",
        "    \"attention_dim\": 360,\n",
        "    \"attention_heads\": 4,\n",
        "    \"feedforward_dim\": 1024,\n",
        "    \"num_layers\": 16,\n",
        "    \"dropout\": 0.2,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 10,\n",
        "    \"epochs\": 20\n",
        "}\n",
        "\n",
        "text_transform = TextTransformBPE(\n",
        "    train_text='train_clean_100_text_clean.txt',\n",
        "    vocab_size=4000\n",
        ")\n",
        "\n",
        "main(hparams, test_batch_size, libri_train_set, libri_test_set)"
      ],
      "metadata": {
        "id": "oQ4p-Jek3BQJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a11b26c-8885-46d1-8fd2-30a08729fc55"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerModel(\n",
            "  (conv_in): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): Linear(in_features=640, out_features=360, bias=True)\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (encoder_layer): MultiSequential(\n",
            "    (0): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (1): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (2): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (3): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (4): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (5): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (6): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (7): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (8): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (9): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (10): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (11): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (12): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (13): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (14): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (15): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (after_norm): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "  (final_layer): Linear(in_features=360, out_features=4001, bias=True)\n",
            ")\n",
            "Num Model Parameters 21844513\n",
            "Tue Jun  7 15:15:22 UTC 2022\n",
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 53.533527\tLR: 0.000040\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 6.817807\tLR: 0.000068\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 6.852149\tLR: 0.000096\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 6.849748\tLR: 0.000124\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 6.754997\tLR: 0.000152\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 6.986618\tLR: 0.000180\n",
            "\n",
            "evaluating...\n",
            "Average loss: 6.8550\n",
            "\n",
            "Tue Jun  7 15:30:47 UTC 2022\n",
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 6.918316\tLR: 0.000200\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 6.991112\tLR: 0.000228\n",
            "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 6.563321\tLR: 0.000256\n",
            "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 6.298690\tLR: 0.000284\n",
            "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 6.150923\tLR: 0.000312\n",
            "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 5.597311\tLR: 0.000340\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 5.4195, Average CER: 0.855388 Average WER: 0.9160\n",
            "\n",
            "Tue Jun  7 15:47:25 UTC 2022\n",
            "Train Epoch: 3 [0/28539 (0%)]\tLoss: 5.800642\tLR: 0.000360\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9facc6a46feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibri_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibri_test_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-bde1c141b7d6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(hparams, test_batch_size, train_url, test_url)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblank_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-6fe520bed79b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "К сожалению колаб имеет ограниченное число GPU-часов, поэтому полноценно все эпохи обучить не удалось (учитывая что были еще максимально неудачные эксперименты)\n",
        "\n",
        "Мое предположение в том, что данная модель из-за большего числа параметров и большего числа сабвордов обучится лучше, для борьбы с переобучением был увеличен дропаут"
      ],
      "metadata": {
        "id": "YrxCX4x1zRK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yHAr0oNO2_6j"
      }
    }
  ]
}