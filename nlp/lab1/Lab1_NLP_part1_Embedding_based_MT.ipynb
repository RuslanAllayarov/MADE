{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eulvfJWl7ueY"
      },
      "source": [
        "# Lab 1\n",
        "\n",
        "\n",
        "## Part 1: Bilingual dictionary induction and unsupervised embedding-based MT (30%)\n",
        "*Note: this homework is based on materials from yandexdataschool [NLP course](https://github.com/yandexdataschool/nlp_course/). Feel free to check this awesome course if you wish to dig deeper.*\n",
        "\n",
        "*Refined by [Nikolay Karpachev](https://www.linkedin.com/in/nikolay-karpachev-b0146a104/)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV4rIjxa7uei"
      },
      "source": [
        "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
        "\n",
        "But even without parallel corpora this system can be good enough (hopefully), in particular for similar languages, e.g. Ukrainian and Russian. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idSYq2GU7uew"
      },
      "source": [
        "### Frament of the Swadesh list for some slavic languages\n",
        "\n",
        "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
        "\n",
        "So we can see some kind of word invariance for different Slavic languages.\n",
        "\n",
        "\n",
        "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
        "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
        "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
        "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
        "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
        "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
        "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
        "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
        "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
        "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
        "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
        "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
        "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
        "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
        "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
        "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
        "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
        "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
        "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
        "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
        "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
        "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
        "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNM3_fjr7ue2"
      },
      "source": [
        "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our for our purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLppwa527ue6"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwGoVhRA7ufP"
      },
      "source": [
        "In this notebook we're going to use pretrained word vectors - FastText (original paper - https://arxiv.org/abs/1607.04606).\n",
        "\n",
        "You can download them from the official [website](https://fasttext.cc/docs/en/crawl-vectors.html). We're going to need embeddings for Russian and Ukrainian languages."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz\n",
        "\n",
        "!wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz\n",
        "!gzip -d cc.uk.300.vec.gz"
      ],
      "metadata": {
        "id": "KV2-MpR-ugq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58ddc77-dad1-41ad-f37f-5a72ae26bda4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-08 11:25:25--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  50.0MB/s    in 25s     \n",
            "\n",
            "2022-04-08 11:25:51 (49.0 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n",
            "--2022-04-08 11:26:31--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1257595219 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.uk.300.vec.gz’\n",
            "\n",
            "cc.uk.300.vec.gz    100%[===================>]   1.17G  40.2MB/s    in 31s     \n",
            "\n",
            "2022-04-08 11:27:02 (39.2 MB/s) - ‘cc.uk.300.vec.gz’ saved [1257595219/1257595219]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading and extracting the vectors, we should be able to load them using the [gensim](https://radimrehurek.com/gensim/) library:"
      ],
      "metadata": {
        "id": "Kwg26PKLv88U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u1JjQv_97ufT"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")\n",
        "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you've loaded the vectors, you can use the `KeyedVectors` interface to get word embeddings and/or query most similar words by embedding:"
      ],
      "metadata": {
        "id": "Sqb_XJhkMyHM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nTkXfT0W7ufk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ff65d5-c691-40af-83fc-9822961a4989"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300,), array([ 0.0033, -0.0322, -0.0519, -0.0808, -0.0131], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "august_embedding = ru_emb[\"август\"]\n",
        "august_embedding.shape, august_embedding[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ru_emb.most_similar([august_embedding])"
      ],
      "metadata": {
        "id": "oQ2kCq-7NQPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b0338e-a958-4cd3-ce6e-495427039191"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('август', 1.0),\n",
              " ('июль', 0.9383153915405273),\n",
              " ('сентябрь', 0.9240028858184814),\n",
              " ('июнь', 0.9222575426101685),\n",
              " ('октябрь', 0.9095538854598999),\n",
              " ('ноябрь', 0.8930036425590515),\n",
              " ('апрель', 0.8729087114334106),\n",
              " ('декабрь', 0.8652557730674744),\n",
              " ('март', 0.8545796275138855),\n",
              " ('февраль', 0.8401416540145874)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The latter function also allows you to vary the amount of closest words via the `topn` argument:"
      ],
      "metadata": {
        "id": "t5EcMMI6pxzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ru_emb.most_similar([august_embedding], topn=3)"
      ],
      "metadata": {
        "id": "bi6AF3z0p9Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e4c839-fb7e-4bdc-a613-3ad7b4e5c0d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('август', 1.0),\n",
              " ('июль', 0.9383153915405273),\n",
              " ('сентябрь', 0.9240028858184814)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another feature of `KeyedVectors` is that it allows to compute embeddings for multiple words simultaneously:"
      ],
      "metadata": {
        "id": "xw345NRXov4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ru_emb[[\"август\", \"сентябрь\"]].shape"
      ],
      "metadata": {
        "id": "86OuYeLYow0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ce7fe4-a7d3-4e78-99df-64ec632663a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything above is true for the embeddings for Ukrainian language."
      ],
      "metadata": {
        "id": "3uGx5zHXQtfo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vdBA8lcg7ufs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50be8523-5eec-4481-dfde-0110c1b008d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('серпень', 0.9999999403953552),\n",
              " ('липень', 0.9096440076828003),\n",
              " ('вересень', 0.901697039604187),\n",
              " ('червень', 0.8992519378662109),\n",
              " ('жовтень', 0.8810408711433411),\n",
              " ('листопад', 0.8787633776664734),\n",
              " ('квітень', 0.8592804670333862),\n",
              " ('грудень', 0.8586863279342651),\n",
              " ('травень', 0.8408110737800598),\n",
              " ('лютий', 0.8256431818008423)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "uk_emb.most_similar([uk_emb[\"серпень\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, russian and ukrainian embeddings were trained independently of each other. This means, that there is no obvious connection between values in embeddings for similar words in Russian and Ukrainian:"
      ],
      "metadata": {
        "id": "F1Dkka5uQ37-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_yJvcKXO7uf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fbda360-f777-46f0-9baa-3d003e64054a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Stepashka.com', 0.2757962942123413),\n",
              " ('ЖИЗНИВадим', 0.25203436613082886),\n",
              " ('2Дмитрий', 0.25048112869262695),\n",
              " ('2012Дмитрий', 0.24829231202602386),\n",
              " ('Ведущий-Алексей', 0.2443869560956955),\n",
              " ('Недопустимость', 0.24435284733772278),\n",
              " ('2Михаил', 0.23981399834156036),\n",
              " ('лексей', 0.23740756511688232),\n",
              " ('комплексн', 0.23695150017738342),\n",
              " ('персональ', 0.2368222028017044)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ru_emb.most_similar([uk_emb[\"серпень\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation"
      ],
      "metadata": {
        "id": "Lia_h7W2qL8C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNdYAR1q7uf6"
      },
      "source": [
        "We'll build a simple translator, which will try to predict the russian embedding from the ukrainian one. For this we'll need a dataset of word pairs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_data_url = \"https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22s_made/homeworks/lab01_unsupervised_translation/uk_ru.train.tsv\"\n",
        "train_data = pd.read_csv(train_data_url, sep=\"\\t\", header=None)\n",
        "train_data.columns = [\"uk\", \"ru\"]\n",
        "print(f\"Train dataset size: {len(train_data)}\")\n",
        "\n",
        "test_data_url = \"https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22s_made/homeworks/lab01_unsupervised_translation/uk_ru.test.tsv\"\n",
        "test_data = pd.read_csv(test_data_url, sep=\"\\t\", header=None)\n",
        "test_data.columns = [\"uk\", \"ru\"]\n",
        "print(f\"Test dataset size: {len(test_data)}\")\n",
        "\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "Kon7ZH6wUYdN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "942caa64-b512-4a89-a5f7-aeda943b6702"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 1927\n",
            "Test dataset size: 400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         uk          ru\n",
              "0  iмовірно    вероятно\n",
              "1     iснує  существует\n",
              "2     iспит     экзамен\n",
              "3     абияк  как-нибудь\n",
              "4       або         или"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d473890c-1ab1-49b1-abb1-8e1a97d3dfd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uk</th>\n",
              "      <th>ru</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iмовірно</td>\n",
              "      <td>вероятно</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>iснує</td>\n",
              "      <td>существует</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>iспит</td>\n",
              "      <td>экзамен</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>абияк</td>\n",
              "      <td>как-нибудь</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>або</td>\n",
              "      <td>или</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d473890c-1ab1-49b1-abb1-8e1a97d3dfd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d473890c-1ab1-49b1-abb1-8e1a97d3dfd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d473890c-1ab1-49b1-abb1-8e1a97d3dfd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our method won't work with unknown words, so let's filter them out:"
      ],
      "metadata": {
        "id": "DYoXmFPanrwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for _, row in train_data.iterrows():\n",
        "    if row[\"uk\"] not in uk_emb or row[\"ru\"] not in ru_emb:\n",
        "        continue\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "train_data = pd.DataFrame(rows)\n",
        "print(f\"Train dataset size: {len(train_data)}\")\n",
        "\n",
        "rows = []\n",
        "for _, row in test_data.iterrows():\n",
        "    if row[\"uk\"] not in uk_emb or row[\"ru\"] not in ru_emb:\n",
        "        continue\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "test_data = pd.DataFrame(rows)\n",
        "print(f\"Test dataset size: {len(test_data)}\")"
      ],
      "metadata": {
        "id": "Ls4h2PrplJID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2be6a4-6467-4302-f32b-2493af6cc422"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 1880\n",
            "Test dataset size: 393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train our model to predict embedding for the russian word from embedding of its ukrainian counterpart. For this reason we split our train and test data into ukrainian and russian words and compute corresponding embeddings to obtain `X` (ukrainian embeddings) and `y` (russian embeddings)."
      ],
      "metadata": {
        "id": "wwjYGFE7Ui0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = uk_emb[train_data[\"uk\"].values], ru_emb[train_data[\"ru\"].values]\n",
        "X_test, Y_test = uk_emb[test_data[\"uk\"].values], ru_emb[test_data[\"ru\"].values]"
      ],
      "metadata": {
        "id": "WR7v7lvFYWYy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZBBNvpz7ugQ"
      },
      "source": [
        "## Embedding space mapping (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Dhk5gL7ugS"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n\\|Wx_i - y_i\\|_2$$\n",
        "\n",
        "or\n",
        "\n",
        "$$W^*= \\arg\\min_W \\|XW^T - Y\\|_F$$\n",
        "\n",
        "where $\\|\\cdot\\|_F$ denotes Frobenius norm.\n",
        "\n",
        "> **Note:** in second formula, $W$ and $x$ seem to have switched places. This happens because the $X$ matrix is composed of objects $x_i$ in *rows* not *columns*, i.e. it is kind of composed of $x_i^T$. This means that $X \\in \\mathbb{R}^{N \\times D}$, where $N$ is the number of items and $D$ is the embedding dimensionality. The same is true for the $Y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acOjDdtL7ugY"
      },
      "source": [
        "$W^*= \\arg\\min_W \\sum_{i=1}^n\\|Wx_i - y_i\\|_2$ looks like simple multiple linear regression without bias. The `sklearn` allows you to turn off the bias in `LinearRegression` via the `fit_intercept` argument (in fact they simply call bias the intercept). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Lb-KN1be7uga"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "# YOUR CODE HERE\n",
        "mapping = LinearRegression(fit_intercept=False).fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7tqJwoY7ugf"
      },
      "source": [
        "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "31SrFSbn7ugi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0f67cf-d816-47e9-f7cb-c8c02e4f5d12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8531432747840881),\n",
              " ('июнь', 0.8402522802352905),\n",
              " ('март', 0.8385884165763855),\n",
              " ('сентябрь', 0.8331484794616699),\n",
              " ('февраль', 0.8311208486557007),\n",
              " ('октябрь', 0.8278019428253174),\n",
              " ('ноябрь', 0.8243728280067444),\n",
              " ('июль', 0.8229618072509766),\n",
              " ('август', 0.8112280368804932),\n",
              " ('январь', 0.8022986650466919)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okSkjk597ugo"
      },
      "source": [
        "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2uY6Y9B7ugt"
      },
      "source": [
        "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in russian embedding space)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zptuho8LAfIE"
      },
      "outputs": [],
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    total = len(pairs)\n",
        "    correct = 0\n",
        "    for i in range(total):\n",
        "        pair = pairs[i]\n",
        "        predicted_vector = mapped_vectors[i]\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        for word, _ in ru_emb.most_similar([mapped_vectors[i]], topn=topn):\n",
        "            if pairs[i][1] == word:\n",
        "                correct += 1\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "duhj9hpv7ugy"
      },
      "outputs": [],
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that our `precision` function accepts lists of pairs of words, whereas we have dataframes. However, it is not a problem: we can get a list (actually, numpy array) of pairs via the `values` property."
      ],
      "metadata": {
        "id": "z5A9tWtnuFx3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0-iyd5gP7ug5"
      },
      "outputs": [],
      "source": [
        "assert precision(test_data.values, X_test) == 0.0\n",
        "assert precision(test_data.values, Y_test) == 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how well our model is doing."
      ],
      "metadata": {
        "id": "7DVV5lqrua_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U-ssEJ3x7uhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd740f8e-2d1b-4e0b-9334-0e80b5ebc7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 precision 62.8%\n",
            "Top-5 precision 79.1%\n"
          ]
        }
      ],
      "source": [
        "top1 = precision(test_data.values, mapping.predict(X_test), 1)\n",
        "print(f\"Top-1 precision {100 * top1:.1f}%\")\n",
        "\n",
        "top5 = precision(test_data.values, mapping.predict(X_test), 5)\n",
        "print(f\"Top-5 precision {100 * top5:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf6Ou8bx7uhH"
      },
      "source": [
        "## Making it better (orthogonal Procrustean problem) (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oLs-drN7uhK"
      },
      "source": [
        "It can be shown that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
        "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
        "\n",
        "$$(W^T)^*= \\arg\\min_{W^T} \\|XW^T - Y\\|_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "$$I \\text{- identity matrix}$$\n",
        "\n",
        "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "$$(W^T)^*=UV^T$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DdFQ7qti7uhL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# YOUR CODE HERE\n",
        "# Compute the orthogonal mapping (W^T)^* as defined in formula above.\n",
        "u, s, vt = np.linalg.svd(X_train.T @ Y_train)\n",
        "mapping = u @ vt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our `mapping` is just a numpy array, meaning that it has no `predict` method. However, from the formulae above we know, that prediction is done using the matrix multiplication:"
      ],
      "metadata": {
        "id": "sehLFmlBysc-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OVOFYYa37uhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e422cd04-ddb3-4abd-f152-a950775b7999"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8245131969451904),\n",
              " ('июнь', 0.805662989616394),\n",
              " ('сентябрь', 0.8055761456489563),\n",
              " ('март', 0.8032935261726379),\n",
              " ('октябрь', 0.7987102270126343),\n",
              " ('июль', 0.7946797013282776),\n",
              " ('ноябрь', 0.7939636707305908),\n",
              " ('август', 0.7938189506530762),\n",
              " ('февраль', 0.7923861145973206),\n",
              " ('декабрь', 0.7715375423431396)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "august = uk_emb[\"серпень\"] @ mapping\n",
        "ru_emb.most_similar([august])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute our precision values and see, whether our trick did improve the results."
      ],
      "metadata": {
        "id": "h4qKCmq7zJDK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "r297sYP37uhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6556bb-eb35-46db-a092-f7da6bf21f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 precision 64.4%\n",
            "Top-5 precision 79.9%\n"
          ]
        }
      ],
      "source": [
        "top1 = precision(test_data.values, X_test @ mapping, 1)\n",
        "print(f\"Top-1 precision {100 * top1:.1f}%\")\n",
        "\n",
        "top5 = precision(test_data.values, X_test @ mapping, 5)\n",
        "print(f\"Top-5 precision {100 * top5:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvUZ72U5AfJg"
      },
      "source": [
        "## Unsupervised embedding-based MT (0.4 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyuVfHBLrJn"
      },
      "source": [
        "Now, let's build our word embeddings-based translator!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPAURW1CMuP7"
      },
      "source": [
        "Firstly, download OPUS Tatoeba corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "F80kUKzQMsDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f1922f-ebba-4180-8b84-1f5b20acc0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-08 11:44:30--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1819128 (1.7M) [application/gzip]\n",
            "Saving to: ‘uk.txt.gz’\n",
            "\n",
            "uk.txt.gz           100%[===================>]   1.73M  2.29MB/s    in 0.8s    \n",
            "\n",
            "2022-04-08 11:44:32 (2.29 MB/s) - ‘uk.txt.gz’ saved [1819128/1819128]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz\n",
        "!gzip -d ./uk.txt.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2MV3VvoVUX5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc620799-250b-47fb-e100-7fffeae49ab2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Я вже закінчу коледж, коли ви вернетеся з Америки.\\n',\n",
              " 'Він наказав мені негайно вийти з кімнати.\\n',\n",
              " 'Як би ти не намагався, ти не вивчиш англійську за два-три місяці.\\n',\n",
              " 'Поки я не подзвонив, він не прийшов.\\n',\n",
              " 'У всесвіті багато галактик.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "with open('./uk.txt', 'r') as f:\n",
        "    uk_corpus = f.readlines()\n",
        "\n",
        "# To save your time and CPU, feel free to use first 1000 sentences of the corpus\n",
        "uk_corpus = uk_corpus[:1000]\n",
        "uk_corpus[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's translate these sentences word-by-word. Before that, however, don't forget to tokenize your sentences. For that you may (or may not) find the `nltk.tokenize.WordPunctTokenizer` to be very useful."
      ],
      "metadata": {
        "id": "oa3dAZHv1wjY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FGksC7l_NMi9"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    translated = []\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    tokenizer = WordPunctTokenizer()\n",
        "\n",
        "    for uk_word in tokenizer.tokenize(sentence):\n",
        "        if uk_word in uk_emb:\n",
        "            ru_word, _ = ru_emb.most_similar([uk_emb[uk_word] @ mapping], topn=1)[0]\n",
        "            translated.append(ru_word)\n",
        "        else:\n",
        "            translated.append(uk_word)\n",
        "\n",
        "    return \" \".join(translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4hbbMy-tNxlf"
      },
      "outputs": [],
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1 , 3\") == \"1 , 3\"\n",
        "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia6I2ce7O_HI"
      },
      "source": [
        "Now you can play with your model and try to get as accurate translations as possible. **Note**: one big issue is out-of-vocabulary words. Try to think of various ways of handling it (you can start with translating each of them to a special **UNK** token and then move to more sophisticated approaches). Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ap1W7ZCeOAVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be4c15e-7b63-42ce-929e-b999daabace1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Я уже закончу колледж , когда мы прибежишь со Америки .\n",
            "Город бомбили враждебные самолеты .\n",
            "Возможно , мной антисоциальный , конечно это не означает , что мной не общаюсь со людьми .\n",
            "Впрочем утра выпала роса .\n",
            "Беда не приходит одна .\n",
            "Посмотри по тот дым .\n",
            "Я заказал два гамбургера .\n",
            "Я не хотел никого обидеть .\n",
            "Гора покрыта снегом .\n",
            "по фотографии во девушки корона не со золота , а со цветов .\n",
            "Во меня То мечта .\n",
            "Я приехал во Японию со Китая .\n",
            "по север находится Шотландия ; по юге — Англия ; по востоке — Уэльс ; и ещe дальше по востоке — северная Ирландия .\n",
            "Его родная страна — Германия .\n",
            "Берн — столица Швейцарии .\n",
            "Он ждал по него к десятой часа .\n",
            "Ты можешь взять ту книгу даром .\n",
            "Такой роман сочинил известный американский писатель .\n",
            "забронировать , будте ласковые , комнату возле международного аэропорта во Торонто .\n",
            "Он знает , что ты его влюбится ?\n",
            "Я знаю , что ты богатый .\n",
            "Те , кто всё забывают , счастливые .\n",
            "Во этой реке опасно плавать .\n",
            "пришел , увидел , победил .\n",
            "Я хожу к школы пешком .\n",
            "Не моя дело !\n",
            "Не забудь билет .\n",
            "Кто он ?\n",
            "Вы будете чай ли кофе ?\n",
            "Он не пойдет по пикник , как и мной .\n",
            "Когда Вы родились ?\n",
            "Это моя любимая песня .\n",
            "мы почти семь со мной .\n",
            "Какой красивый сегодня месяц !\n",
            "Я против любой – которых войны .\n",
            "поверхность воздушной шары — неевклідовий пространство , потому для неё не выполняются правила симметрической геометрии .\n",
            "Говорят , что американцы считают количество денег , какую зарабатывает женщина , мерилом его умение .\n",
            "Можно мной примірю это платье ?\n",
            "Если будет красивая погода , мы доберёмся туда завтра .\n",
            "Это был злой заяц .\n",
            "Один , два , три , четыре , аш со пять , восемь , семь , восемь , девять со пять , десять .\n",
            "Кто во любви не знает , тот горя не знает .\n",
            "Его иметь волнуется за него .\n",
            "Я уважаю тех , кто старается со всех сил .\n",
            "необычайная дружба переросла во глубокое любовь .\n",
            "Рейчел аш со То много молока каждый день .\n",
            "Он вор .\n",
            "Шумового загрязнение можно было бы позбігнути только если бы люди были более чувствительны к окружающей среды .\n",
            "чай со лимоном , будте ласковые .\n",
            "Не путать желание со влюбленностью .\n",
            "Я бы со удовольствием сочинил сотни сложноподчинённые во Tatoeb со и , конечно во меня То дела .\n",
            "Дайте мне чашечку кофе .\n",
            "ведь же ты никогда мне о это не рассказывала !\n",
            "Во тебя будут проблемы , если твои родители узнают .\n",
            "Запах роз наполнил комнату .\n",
            "Как во тебя дела ?\n",
            "Это мои штаны .\n",
            "НЕт , спасибо .\n",
            "Я не понимаю , почему Германия победила по Евровидении .\n",
            "Добрый вечер .\n",
            "Со юбілеєм Алексея Палашка поприветствовал президент Белоруссии Александр Лукашенко .\n",
            "Млечный путь — широкий пояс со далеких звёзд , каждая звезда — солнце , такое как наше .\n",
            "удивительно видеть рок – звёзд со галстук !\n",
            "всё печенье во форме звёзд .\n",
            "ЧТо мне одеть — штаны ли юбку ?\n",
            "Краусс утверждал — известный московский скульптор .\n",
            "Ой был злой кролик .\n",
            "Можешь взять любой – который , что тебе к отвратиться .\n",
            "Конечно мной пойду .\n",
            "шелковичные прядут коконы .\n",
            "ЧТо бы ты сделала , если бы во тебя было , замечу , десять тысяч долларов ?\n",
            "Он думает , что он кто-то , а действительно он никто .\n",
            "она очень гордится своею коллекцией марок .\n",
            "Он очень простой ...\n",
            "Какая ты добра !\n",
            "Как мной за тобой соскучился !\n",
            "Это всё , что мной знаю .\n",
            "Ты ведёшь дневник ?\n",
            "Тебе решать .\n",
            "Это почта , а то — банк .\n",
            "Это всё , что мной хочу сделать .\n",
            "Я впервые смотрю такой страшный фильм .\n",
            "Этa песня напоминает мне о дом .\n",
            "Хироси здесь ?\n",
            "Меня зовут Эдди .\n",
            "Как женщина живет , так она и умрет .\n",
            "Я здесь уже две часа .\n",
            "Мне надо извиниться перед Нб .\n",
            "Сегодня мной видел скворца .\n",
            "« Сколько стоить та носовая косыночка ?» — « тринадцать со двадцать аш со пять центов ».\n",
            "солдаты медведи , как правило , очень опасные .\n",
            "Он быстро устает .\n",
            "остальные готовы .\n",
            "Он скучает по своей семь со мье .\n",
            "« Спасибо », — « по здоровье со мной ».\n",
            "Я ещe не знаю своего адреса , мной определенный момент буду жить во подруги .\n",
            "Амазонка — вторая по длине река во мире после Нила .\n",
            "А если увидишь Тима , передай ему от меня поздравления .\n",
            "закрой за собой дверь .\n",
            "Держи при себе словарь .\n"
          ]
        }
      ],
      "source": [
        "for sent in uk_corpus[::10]:\n",
        "    print(translate(sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to use a [stemmer for the Ukrainian language](https://github.com/Desklop/Uk_Stemmer) (this may reduce the number of words that the model cannot translate, but the translation itself may suffer, because most likely all words will be translated in their initial form"
      ],
      "metadata": {
        "id": "j6Hebsntrojs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Desklop/Uk_Stemmer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF9bdiaurLna",
        "outputId": "70b19a26-cda7-432f-90fc-1e44a886ab85"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Desklop/Uk_Stemmer\n",
            "  Cloning https://github.com/Desklop/Uk_Stemmer to /tmp/pip-req-build-nanyua1l\n",
            "  Running command git clone -q https://github.com/Desklop/Uk_Stemmer /tmp/pip-req-build-nanyua1l\n",
            "Building wheels for collected packages: uk-stemmer\n",
            "  Building wheel for uk-stemmer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uk-stemmer: filename=uk_stemmer-1.0-py3-none-any.whl size=9511 sha256=eb99ecbaafae21561c3ee626ead0f88b37ffe21298a60c71737d3b67a6a15669\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-29racx6b/wheels/40/53/2f/982431dc2aff61a4eb52a030950bbbdef0d9178114373d6c0e\n",
            "Successfully built uk-stemmer\n",
            "Installing collected packages: uk-stemmer\n",
            "Successfully installed uk-stemmer-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from uk_stemmer import UkStemmer\n",
        "\n",
        "stemmer = UkStemmer()\n",
        "\n",
        "test_string = 'Привіт, як твої справи? Зберігайте спокойствіе. Будь ласка, зберігайте спокій.'\n",
        "\n",
        "prepare_test_string = test_string.lower()\n",
        "words = re.split(r'(\\W)', prepare_test_string)\n",
        "words = [word for word in words if word != '']\n",
        "\n",
        "for i in range(len(words)):\n",
        "    words[i] = stemmer.stem_word(words[i])\n",
        "\n",
        "stem_test_string = ''.join(words)\n",
        "\n",
        "print(stem_test_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kP6u02Yrpk9",
        "outputId": "cf7ce261-9cb2-4a2c-baa4-153576bd47c3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "привіт, як тво справ? зберігайт спокойств. буд ласк, зберігайт спок.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_with_stem(sentence):\n",
        "\n",
        "    stemmer = UkStemmer()\n",
        "\n",
        "    prepare_sentence = sentence.lower()\n",
        "    words = re.split(r'(\\W)', prepare_sentence)\n",
        "    words = [word for word in words if word != '']\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        words[i] = stemmer.stem_word(words[i])\n",
        "\n",
        "    translated = []\n",
        "    \n",
        "    for uk_word in words:\n",
        "        if uk_word in uk_emb:\n",
        "            ru_word, _ = ru_emb.most_similar([uk_emb[uk_word] @ mapping], topn=1)[0]\n",
        "            translated.append(ru_word)\n",
        "        else:\n",
        "            translated.append(uk_word)\n",
        "\n",
        "    return re.sub(r'\\s+', ' ', \" \".join(translated))"
      ],
      "metadata": {
        "id": "aTRPpgwUz0Tz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in uk_corpus[::10]:\n",
        "    print(f'UK: \\n {sent.strip()}')\n",
        "    print(f'RU (with stem): \\n {translate_with_stem(sent)}')\n",
        "    print(f'RU (without stem): \\n {translate(sent)} \\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImqHNr6R0cSn",
        "outputId": "6786a7cc-00e0-42a2-a429-50c031a323c6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UK: \n",
            " Я вже закінчу коледж, коли ви вернетеся з Америки.\n",
            "RU (with stem): \n",
            " мной уже закончил колледж , Желтухинский мы возвратишь со океании . \n",
            "RU (without stem): \n",
            " Я уже закончу колледж , когда мы прибежишь со Америки . \n",
            "\n",
            "UK: \n",
            " Місто бомбардували ворожі літаки.\n",
            "RU (with stem): \n",
            " городов бомбардув ворож самолет . \n",
            "RU (without stem): \n",
            " Город бомбили враждебные самолеты . \n",
            "\n",
            "UK: \n",
            " Можливо, я антисоціальний, але це не означає, що я не спілкуюся з людьми.\n",
            "RU (with stem): \n",
            " возможност , мной антисоціальн , ым это не означить , что мной не программаДля со людьми . \n",
            "RU (without stem): \n",
            " Возможно , мной антисоциальный , конечно это не означает , что мной не общаюсь со людьми . \n",
            "\n",
            "UK: \n",
            " Цього ранку випала роса.\n",
            "RU (with stem): \n",
            " этого.Если дартсмен обжиг анг . \n",
            "RU (without stem): \n",
            " Впрочем утра выпала роса . \n",
            "\n",
            "UK: \n",
            " Біда не приходить одна.\n",
            "RU (with stem): \n",
            " бед не прихожу мын . \n",
            "RU (without stem): \n",
            " Беда не приходит одна . \n",
            "\n",
            "UK: \n",
            " Подивися на той дим.\n",
            "RU (with stem): \n",
            " удивление по то дым . \n",
            "RU (without stem): \n",
            " Посмотри по тот дым . \n",
            "\n",
            "UK: \n",
            " Я замовив два гамбургера.\n",
            "RU (with stem): \n",
            " мной заказ два гамбургер . \n",
            "RU (without stem): \n",
            " Я заказал два гамбургера . \n",
            "\n",
            "UK: \n",
            " Я не хотів нікого образити.\n",
            "RU (with stem): \n",
            " мной не тоб никнэйм образит . \n",
            "RU (without stem): \n",
            " Я не хотел никого обидеть . \n",
            "\n",
            "UK: \n",
            " Гора вкрита снігом.\n",
            "RU (with stem): \n",
            " тавы вкрит снег . \n",
            "RU (without stem): \n",
            " Гора покрыта снегом . \n",
            "\n",
            "UK: \n",
            " На фотографії в дівчини корона не з золота, а з квітів.\n",
            "RU (with stem): \n",
            " по фотография во девушка корон не со золото , а со сент . \n",
            "RU (without stem): \n",
            " по фотографии во девушки корона не со золота , а со цветов . \n",
            "\n",
            "UK: \n",
            " У мене є мрія.\n",
            "RU (with stem): \n",
            " во ен То жой . \n",
            "RU (without stem): \n",
            " Во меня То мечта . \n",
            "\n",
            "UK: \n",
            " Я приїхав у Японію з Китаю.\n",
            "RU (with stem): \n",
            " мной приїх во нихон со кит . \n",
            "RU (without stem): \n",
            " Я приехал во Японию со Китая . \n",
            "\n",
            "UK: \n",
            " На півночі знаходиться Шотландія; на півдні — Англія; на заході — Уельс; і ще далі на заході — Північна Ірландія.\n",
            "RU (with stem): \n",
            " по режья находиться шотланд ; по півдн — англ ; по мероприятия — англо-саксонский ; и ещe декалитров по мероприятия — север ірланд . \n",
            "RU (without stem): \n",
            " по север находится Шотландия ; по юге — Англия ; по востоке — Уэльс ; и ещe дальше по востоке — северная Ирландия . \n",
            "\n",
            "UK: \n",
            " Його рідна країна — Німеччина.\n",
            "RU (with stem): \n",
            " ег родно стран — німеччин . \n",
            "RU (without stem): \n",
            " Его родная страна — Германия . \n",
            "\n",
            "UK: \n",
            " Берн — столиця Швейцарії.\n",
            "RU (with stem): \n",
            " Уотертаун — столицы швейцарі . \n",
            "RU (without stem): \n",
            " Берн — столица Швейцарии . \n",
            "\n",
            "UK: \n",
            " Він чекав на нього до десятої години.\n",
            "RU (with stem): \n",
            " он чек по сообщество.Десятки к двести часов . \n",
            "RU (without stem): \n",
            " Он ждал по него к десятой часа . \n",
            "\n",
            "UK: \n",
            " Ти можеш взяти цю книгу даром.\n",
            "RU (with stem): \n",
            " ты можешь взят ту книг дар . \n",
            "RU (without stem): \n",
            " Ты можешь взять ту книгу даром . \n",
            "\n",
            "UK: \n",
            " Цей роман написав відомий американський письменник.\n",
            "RU (with stem): \n",
            " это роман надпись подтвержается австралия писатель . \n",
            "RU (without stem): \n",
            " Такой роман сочинил известный американский писатель . \n",
            "\n",
            "UK: \n",
            " Забронюйте, будьте ласкаві, кімнату біля міжнародного аеропорту в Торонто.\n",
            "RU (with stem): \n",
            " забронюйт , будьт приласкал , комнат обыкн российско-израильских аэропорт во торонт . \n",
            "RU (without stem): \n",
            " забронировать , будте ласковые , комнату возле международного аэропорта во Торонто . \n",
            "\n",
            "UK: \n",
            " Він знає, що ти його кохаєш?\n",
            "RU (with stem): \n",
            " он кто , что ты ег влюбится ? \n",
            "RU (without stem): \n",
            " Он знает , что ты его влюбится ? \n",
            "\n",
            "UK: \n",
            " Я знаю, що ти багатий.\n",
            "RU (with stem): \n",
            " мной кто , что ты богатый . \n",
            "RU (without stem): \n",
            " Я знаю , что ты богатый . \n",
            "\n",
            "UK: \n",
            " Ті, хто все забувають, щасливі.\n",
            "RU (with stem): \n",
            " те , кто всё забувают , счастлив . \n",
            "RU (without stem): \n",
            " Те , кто всё забывают , счастливые . \n",
            "\n",
            "UK: \n",
            " В цій річці небезпечно плавати.\n",
            "RU (with stem): \n",
            " во зти річц опасное плав . \n",
            "RU (without stem): \n",
            " Во этой реке опасно плавать . \n",
            "\n",
            "UK: \n",
            " Прийшов, побачив, переміг.\n",
            "RU (with stem): \n",
            " приехал , увидь , победил . \n",
            "RU (without stem): \n",
            " пришел , увидел , победил . \n",
            "\n",
            "UK: \n",
            " Я ходжу до школи пішки.\n",
            "RU (with stem): \n",
            " мной ходж к школы пішк . \n",
            "RU (without stem): \n",
            " Я хожу к школы пешком . \n",
            "\n",
            "UK: \n",
            " Не твоя справа!\n",
            "RU (with stem): \n",
            " не замыс дел ! \n",
            "RU (without stem): \n",
            " Не моя дело ! \n",
            "\n",
            "UK: \n",
            " Не забудь квиток.\n",
            "RU (with stem): \n",
            " не соседий билет . \n",
            "RU (without stem): \n",
            " Не забудь билет . \n",
            "\n",
            "UK: \n",
            " Хто він?\n",
            "RU (with stem): \n",
            " кто он ? \n",
            "RU (without stem): \n",
            " Кто он ? \n",
            "\n",
            "UK: \n",
            " Ви будете чай чи каву?\n",
            "RU (with stem): \n",
            " мы будет ча ли хипстерских ? \n",
            "RU (without stem): \n",
            " Вы будете чай ли кофе ? \n",
            "\n",
            "UK: \n",
            " Він не піде на пікнік, як і я.\n",
            "RU (with stem): \n",
            " он не под по пикник , как и мной . \n",
            "RU (without stem): \n",
            " Он не пойдет по пикник , как и мной . \n",
            "\n",
            "UK: \n",
            " Коли Ви народилися?\n",
            "RU (with stem): \n",
            " Желтухинский мы народил ? \n",
            "RU (without stem): \n",
            " Когда Вы родились ? \n",
            "\n",
            "UK: \n",
            " Це моя улюблена пісня.\n",
            "RU (with stem): \n",
            " это Вче улюблен песня . \n",
            "RU (without stem): \n",
            " Это моя любимая песня . \n",
            "\n",
            "UK: \n",
            " Ми майже сім’я.\n",
            "RU (with stem): \n",
            " мы перебрасываю семь со мной . \n",
            "RU (without stem): \n",
            " мы почти семь со мной . \n",
            "\n",
            "UK: \n",
            " Який гарний сьогодні місяць!\n",
            "RU (with stem): \n",
            " как классны сегодня месяц ! \n",
            "RU (without stem): \n",
            " Какой красивый сегодня месяц ! \n",
            "\n",
            "UK: \n",
            " Я проти будь-яких війн.\n",
            "RU (with stem): \n",
            " мной прот ул.Боровая – как войны . \n",
            "RU (without stem): \n",
            " Я против любой – которых войны . \n",
            "\n",
            "UK: \n",
            " Поверхня повітряної кулі — неевклідовий простір, тому для неї не виконуються правила евклідової геометрії.\n",
            "RU (with stem): \n",
            " поверхности повітрян ой — неевклідов пространство , полутом для не не виконуют правил евклідов молекулярно-кинетической . \n",
            "RU (without stem): \n",
            " поверхность воздушной шары — неевклідовий пространство , потому для неё не выполняются правила симметрической геометрии . \n",
            "\n",
            "UK: \n",
            " Кажуть, що американці вважають кількість грошей, яку заробляє людина, мірилом його уміння.\n",
            "RU (with stem): \n",
            " мол , что америка считающие количество деньга , как зарабатывают человек , мерило ег умінн . \n",
            "RU (without stem): \n",
            " Говорят , что американцы считают количество денег , какую зарабатывает женщина , мерилом его умение . \n",
            "\n",
            "UK: \n",
            " Можна я примірю це плаття?\n",
            "RU (with stem): \n",
            " можн мной пример это платт ? \n",
            "RU (without stem): \n",
            " Можно мной примірю это платье ? \n",
            "\n",
            "UK: \n",
            " Якщо буде гарна погода, ми доберемося туди завтра.\n",
            "RU (with stem): \n",
            " Есл ул.Боровая классны погод , мы доберем въе завтр . \n",
            "RU (without stem): \n",
            " Если будет красивая погода , мы доберёмся туда завтра . \n",
            "\n",
            "UK: \n",
            " Це був злий заєць.\n",
            "RU (with stem): \n",
            " это был утю заєц . \n",
            "RU (without stem): \n",
            " Это был злой заяц . \n",
            "\n",
            "UK: \n",
            " Один, два, три, чотири, п'ять, шість, сім, вісім, дев'ять, десять.\n",
            "RU (with stem): \n",
            " один , два , три , десятеро , аш пят , семь , семь , таа , девять пят , десятин . \n",
            "RU (without stem): \n",
            " Один , два , три , четыре , аш со пять , восемь , семь , восемь , девять со пять , десять . \n",
            "\n",
            "UK: \n",
            " Хто в любові не знається, той горя не знає.\n",
            "RU (with stem): \n",
            " кто во учтив не знает , то тавы не кто . \n",
            "RU (without stem): \n",
            " Кто во любви не знает , тот горя не знает . \n",
            "\n",
            "UK: \n",
            " Його мати хвилюється за нього.\n",
            "RU (with stem): \n",
            " ег мат хвилюєт за сообщество.Десятки . \n",
            "RU (without stem): \n",
            " Его иметь волнуется за него . \n",
            "\n",
            "UK: \n",
            " Я поважаю тих, хто старається з усіх сил.\n",
            "RU (with stem): \n",
            " мной уважительную тех , кто стараєт со ен сил . \n",
            "RU (without stem): \n",
            " Я уважаю тех , кто старается со всех сил . \n",
            "\n",
            "UK: \n",
            " Їхня дружба переросла у глибоке кохання.\n",
            "RU (with stem): \n",
            " их дружба переросл во глубокий состраданье . \n",
            "RU (without stem): \n",
            " необычайная дружба переросла во глубокое любовь . \n",
            "\n",
            "UK: \n",
            " Кейт п’є багато молока кожен день.\n",
            "RU (with stem): \n",
            " джастин аш со То богатый самогончик каждый ден . \n",
            "RU (without stem): \n",
            " Рейчел аш со То много молока каждый день . \n",
            "\n",
            "UK: \n",
            " Він злодій.\n",
            "RU (with stem): \n",
            " он беспредельщик . \n",
            "RU (without stem): \n",
            " Он вор . \n",
            "\n",
            "UK: \n",
            " Шумового забруднення можна було б позбігнути тільки якщо б люди були більш чутливими до навколишнього середовища.\n",
            "RU (with stem): \n",
            " шумов загрязнение можн д.3а бы позбігнут только Есл бы люд д.3а более чувствит к окружающую сред . \n",
            "RU (without stem): \n",
            " Шумового загрязнение можно было бы позбігнути только если бы люди были более чувствительны к окружающей среды . \n",
            "\n",
            "UK: \n",
            " Чай з лимоном, будьте ласкаві.\n",
            "RU (with stem): \n",
            " ча со лимон , будьт приласкал . \n",
            "RU (without stem): \n",
            " чай со лимоном , будте ласковые . \n",
            "\n",
            "UK: \n",
            " Не плутай бажання з коханням.\n",
            "RU (with stem): \n",
            " не плута желание со состраданье . \n",
            "RU (without stem): \n",
            " Не путать желание со влюбленностью . \n",
            "\n",
            "UK: \n",
            " Я би з задоволенням написав сотні речень в Tatoeb’і, але в мене є справи.\n",
            "RU (with stem): \n",
            " мной бы со удовольствие надпись сотня рифмовку во tatoeb со и , ым во ен То дел . \n",
            "RU (without stem): \n",
            " Я бы со удовольствием сочинил сотни сложноподчинённые во Tatoeb со и , конечно во меня То дела . \n",
            "\n",
            "UK: \n",
            " Дайте мені філіжанку кави.\n",
            "RU (with stem): \n",
            " дайт ен філіжанк хипстерских . \n",
            "RU (without stem): \n",
            " Дайте мне чашечку кофе . \n",
            "\n",
            "UK: \n",
            " Але ж ти ніколи мені про це не розповідала!\n",
            "RU (with stem): \n",
            " ым же ты никогда ен о это не розповідал ! \n",
            "RU (without stem): \n",
            " ведь же ты никогда мне о это не рассказывала ! \n",
            "\n",
            "UK: \n",
            " У тебе будуть проблеми, якщо твої батьки довідаються.\n",
            "RU (with stem): \n",
            " во е-е будут проблем , Есл замыс родители довідают . \n",
            "RU (without stem): \n",
            " Во тебя будут проблемы , если твои родители узнают . \n",
            "\n",
            "UK: \n",
            " Запах троянд наповнив кімнату.\n",
            "RU (with stem): \n",
            " нoг роз наповн комнат . \n",
            "RU (without stem): \n",
            " Запах роз наполнил комнату . \n",
            "\n",
            "UK: \n",
            " Як у тебе справи?\n",
            "RU (with stem): \n",
            " как во е-е дел ? \n",
            "RU (without stem): \n",
            " Как во тебя дела ? \n",
            "\n",
            "UK: \n",
            " Це мої штани.\n",
            "RU (with stem): \n",
            " это Вче кафтанчик . \n",
            "RU (without stem): \n",
            " Это мои штаны . \n",
            "\n",
            "UK: \n",
            " Ні, дякую.\n",
            "RU (with stem): \n",
            " ни , дьячок . \n",
            "RU (without stem): \n",
            " НЕт , спасибо . \n",
            "\n",
            "UK: \n",
            " Я не розумію, чому Німеччина перемогла на Євробаченні.\n",
            "RU (with stem): \n",
            " мной не разум , чо німеччин перемогл по євробаченн . \n",
            "RU (without stem): \n",
            " Я не понимаю , почему Германия победила по Евровидении . \n",
            "\n",
            "UK: \n",
            " Добрий вечір.\n",
            "RU (with stem): \n",
            " доброт вечер . \n",
            "RU (without stem): \n",
            " Добрый вечер . \n",
            "\n",
            "UK: \n",
            " З юбілеєм Олексія Дударева привітав Президент Білорусі Олександр Лукашенко.\n",
            "RU (with stem): \n",
            " со юбіле олекс дударев привет президент сибиряк борис лукашенк . \n",
            "RU (without stem): \n",
            " Со юбілеєм Алексея Палашка поприветствовал президент Белоруссии Александр Лукашенко . \n",
            "\n",
            "UK: \n",
            " Чумацький шлях — широкий пояс із далеких зірок, кожна зірка — сонце, таке як наше.\n",
            "RU (with stem): \n",
            " чумацьк путь — схематичную пояс со далек звёзд , каждая звезда — солнце , так как наш . \n",
            "RU (without stem): \n",
            " Млечный путь — широкий пояс со далеких звёзд , каждая звезда — солнце , такое как наше . \n",
            "\n",
            "UK: \n",
            " Незвичайно бачити рок-зірок з краваткою!\n",
            "RU (with stem): \n",
            " незвичайн видеть рок – звёзд со краватк ! \n",
            "RU (without stem): \n",
            " удивительно видеть рок – звёзд со галстук ! \n",
            "\n",
            "UK: \n",
            " Усе печиво у формі зірок.\n",
            "RU (with stem): \n",
            " ен выпекал во форм звёзд . \n",
            "RU (without stem): \n",
            " всё печенье во форме звёзд . \n",
            "\n",
            "UK: \n",
            " Що мені вдягнути — штани чи спідницю?\n",
            "RU (with stem): \n",
            " что ен вдягнут — кафтанчик ли спідниц ? \n",
            "RU (without stem): \n",
            " ЧТо мне одеть — штаны ли юбку ? \n",
            "\n",
            "UK: \n",
            " Гартман Вітвер — відомий львівський скульптор.\n",
            "RU (with stem): \n",
            " гартман вітвер — подтвержается зеленоградский скульптор . \n",
            "RU (without stem): \n",
            " Краусс утверждал — известный московский скульптор . \n",
            "\n",
            "UK: \n",
            " То був злий кролик.\n",
            "RU (with stem): \n",
            " то был утю кролик . \n",
            "RU (without stem): \n",
            " Ой был злой кролик . \n",
            "\n",
            "UK: \n",
            " Можеш взяти будь-який, що тобі до сподоби.\n",
            "RU (with stem): \n",
            " можешь взят ул.Боровая – как , что олн к понравятся . \n",
            "RU (without stem): \n",
            " Можешь взять любой – который , что тебе к отвратиться . \n",
            "\n",
            "UK: \n",
            " Звичайно я піду.\n",
            "RU (with stem): \n",
            " обыкновенная мной под . \n",
            "RU (without stem): \n",
            " Конечно мной пойду . \n",
            "\n",
            "UK: \n",
            " Шовкопряди прядуть кокони.\n",
            "RU (with stem): \n",
            " шелковичный прядут кокон . \n",
            "RU (without stem): \n",
            " шелковичные прядут коконы . \n",
            "\n",
            "UK: \n",
            " Що б ти зробила, якщо б у тебе було, скажім, десять тисяч доларів?\n",
            "RU (with stem): \n",
            " что бы ты зробил , Есл бы во е-е д.3а , намекну , десятин тысяч доллар ? \n",
            "RU (without stem): \n",
            " ЧТо бы ты сделала , если бы во тебя было , замечу , десять тысяч долларов ? \n",
            "\n",
            "UK: \n",
            " Він думає, що він хтось, а насправді він ніхто.\n",
            "RU (with stem): \n",
            " он дум , что он кто , а подоплёке он ктот . \n",
            "RU (without stem): \n",
            " Он думает , что он кто-то , а действительно он никто . \n",
            "\n",
            "UK: \n",
            " Вона дуже пишається своєю колекцією марок.\n",
            "RU (with stem): \n",
            " ай ой пишаєт свое колекціє марок . \n",
            "RU (without stem): \n",
            " она очень гордится своею коллекцией марок . \n",
            "\n",
            "UK: \n",
            " Він дуже простий...\n",
            "RU (with stem): \n",
            " он ой простой . . . \n",
            "RU (without stem): \n",
            " Он очень простой ... \n",
            "\n",
            "UK: \n",
            " Яка ти добра!\n",
            "RU (with stem): \n",
            " как ты доброт ! \n",
            "RU (without stem): \n",
            " Какая ты добра ! \n",
            "\n",
            "UK: \n",
            " Як я за тобою скучив!\n",
            "RU (with stem): \n",
            " как мной за олн скуч ! \n",
            "RU (without stem): \n",
            " Как мной за тобой соскучился ! \n",
            "\n",
            "UK: \n",
            " Це все, що я знаю.\n",
            "RU (with stem): \n",
            " это всё , что мной кто . \n",
            "RU (without stem): \n",
            " Это всё , что мной знаю . \n",
            "\n",
            "UK: \n",
            " Ти ведеш щоденник?\n",
            "RU (with stem): \n",
            " ты ведёшь дневник ? \n",
            "RU (without stem): \n",
            " Ты ведёшь дневник ? \n",
            "\n",
            "UK: \n",
            " Тобі вирішувати.\n",
            "RU (with stem): \n",
            " олн вирішув . \n",
            "RU (without stem): \n",
            " Тебе решать . \n",
            "\n",
            "UK: \n",
            " Це пошта, а то — банк.\n",
            "RU (with stem): \n",
            " это почт , а то — банк . \n",
            "RU (without stem): \n",
            " Это почта , а то — банк . \n",
            "\n",
            "UK: \n",
            " Це все, що я хочу зробити.\n",
            "RU (with stem): \n",
            " это всё , что мной хоть сделать . \n",
            "RU (without stem): \n",
            " Это всё , что мной хочу сделать . \n",
            "\n",
            "UK: \n",
            " Я вперше дивлюся такий страшний фільм.\n",
            "RU (with stem): \n",
            " мной прежде морал так страшный фильм . \n",
            "RU (without stem): \n",
            " Я впервые смотрю такой страшный фильм . \n",
            "\n",
            "UK: \n",
            " Ця пісня нагадує мені про дім.\n",
            "RU (with stem): \n",
            " та песня напомнить ен о дом . \n",
            "RU (without stem): \n",
            " Этa песня напоминает мне о дом . \n",
            "\n",
            "UK: \n",
            " Хіросі тут?\n",
            "RU (with stem): \n",
            " хірос здесь ? \n",
            "RU (without stem): \n",
            " Хироси здесь ? \n",
            "\n",
            "UK: \n",
            " Мене звуть Джек.\n",
            "RU (with stem): \n",
            " ен звут джэк . \n",
            "RU (without stem): \n",
            " Меня зовут Эдди . \n",
            "\n",
            "UK: \n",
            " Як людина живе, так вона і помре.\n",
            "RU (with stem): \n",
            " как человек жил , так ай и помр . \n",
            "RU (without stem): \n",
            " Как женщина живет , так она и умрет . \n",
            "\n",
            "UK: \n",
            " Я тут уже дві години.\n",
            "RU (with stem): \n",
            " мной здесь ой две часов . \n",
            "RU (without stem): \n",
            " Я здесь уже две часа . \n",
            "\n",
            "UK: \n",
            " Мені треба вибачитись перед Ен.\n",
            "RU (with stem): \n",
            " ен Пресвитеры вибачит перед ен . \n",
            "RU (without stem): \n",
            " Мне надо извиниться перед Нб . \n",
            "\n",
            "UK: \n",
            " Сьогодні я бачив шпака.\n",
            "RU (with stem): \n",
            " сегодня мной чьто скворец . \n",
            "RU (without stem): \n",
            " Сегодня мной видел скворца . \n",
            "\n",
            "UK: \n",
            " «Скільки коштує ця носова хусточка?» — «Дев'яносто п'ять центів».\n",
            "RU (with stem): \n",
            " « скільк кошт та нос- хусточк ? » — « девять яност аш пят цент » . \n",
            "RU (without stem): \n",
            " « Сколько стоить та носовая косыночка ?» — « тринадцать со двадцать аш со пять центов ». \n",
            "\n",
            "UK: \n",
            " Ранені ведмеді, як правило, дуже небезпечні.\n",
            "RU (with stem): \n",
            " раненый ведмед , как правил , ой опасное . \n",
            "RU (without stem): \n",
            " солдаты медведи , как правило , очень опасные . \n",
            "\n",
            "UK: \n",
            " Він швидко втомлюється.\n",
            "RU (with stem): \n",
            " он скорост втомлюєт . \n",
            "RU (without stem): \n",
            " Он быстро устает . \n",
            "\n",
            "UK: \n",
            " Усі готові.\n",
            "RU (with stem): \n",
            " ен гот . \n",
            "RU (without stem): \n",
            " остальные готовы . \n",
            "\n",
            "UK: \n",
            " Він скучає по своїй сім'ї.\n",
            "RU (with stem): \n",
            " он скуч по сво семь мье . \n",
            "RU (without stem): \n",
            " Он скучает по своей семь со мье . \n",
            "\n",
            "UK: \n",
            " «Дякую», — «На здоров'я».\n",
            "RU (with stem): \n",
            " « дьячок » , — « по здор мной » . \n",
            "RU (without stem): \n",
            " « Спасибо », — « по здоровье со мной ». \n",
            "\n",
            "UK: \n",
            " Я ще не знаю своєї адреси, я певний час буду жити в подруги.\n",
            "RU (with stem): \n",
            " мной ещe не кто свое бй , мной определенн момент ул.Боровая жиз во подруг . \n",
            "RU (without stem): \n",
            " Я ещe не знаю своего адреса , мной определенный момент буду жить во подруги . \n",
            "\n",
            "UK: \n",
            " Амазонка— друга по довжині ріка в світі після Ніла.\n",
            "RU (with stem): \n",
            " амазонк — приятель по длин год во мир подт Шиа . \n",
            "RU (without stem): \n",
            " Амазонка — вторая по длине река во мире после Нила . \n",
            "\n",
            "UK: \n",
            " А якщо побачиш Тома, передай йому від мене вітання.\n",
            "RU (with stem): \n",
            " а Есл увидишь полутом , завтра ующий от ен вітанн . \n",
            "RU (without stem): \n",
            " А если увидишь Тима , передай ему от меня поздравления . \n",
            "\n",
            "UK: \n",
            " Закрий за собою двері.\n",
            "RU (with stem): \n",
            " закрепл за ебя дверь . \n",
            "RU (without stem): \n",
            " закрой за собой дверь . \n",
            "\n",
            "UK: \n",
            " Тримай при собі словник.\n",
            "RU (with stem): \n",
            " прислонится при ебя словарь . \n",
            "RU (without stem): \n",
            " Держи при себе словарь . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results got worse, but it was worth a try)"
      ],
      "metadata": {
        "id": "__Y0x7Jc2h8N"
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Lab1_NLP_part1_Embedding_based_MT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}